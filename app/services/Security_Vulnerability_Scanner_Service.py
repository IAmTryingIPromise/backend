"""
Security Vulnerability Scanner Service
Integrates CPE-based vulnerability scanning with the existing database models
"""

import asyncio
import aiohttp
import json
import csv
import os
import re
from typing import Dict, List, Optional, Any, Tuple, Set
import time
from functools import lru_cache
from collections import defaultdict
import logging
from fuzzywuzzy import fuzz
from sqlalchemy.orm import Session
from sqlalchemy.exc import IntegrityError

# Import your existing models and database dependencies
from app.models.asset import Asset
from app.models.cve import CVE
from app.models.cwe import CWE
from app.models.capec import CAPEC
from app.models.attack import Attack
from app.models.relations import AssetCVERelation, CVECWERelation, CWECAPECRelation, CAPECAttackRelation
from app.database import get_db
from app.crud import asset_crud, cve_crud, cwe_crud, capec_crud, attack_crud

# Configure logging
logging.getLogger('aiohttp').setLevel(logging.WARNING)


def is_device_vulnerable(cve_item, cpe_name):
    """Check if device is vulnerable to the given CVE."""
    cpe_name = cpe_name.replace('-', '*')
    for configs in cve_item["cve"]["configurations"]:
        for node in configs["nodes"]:
            for cpe_match in node["cpeMatch"]:
                if (cpe_match.get("criteria") == cpe_name and 
                    cpe_match.get("vulnerable") == True):
                    return True
    return False


class OptimizedCPEMatcher:
    """Advanced CPE matcher with fuzzy logic and indexing"""
    
    def __init__(self, devices_data: List[Dict]):
        self.devices_data = devices_data
        self.vendor_index = defaultdict(list)
        self.model_index = defaultdict(list)
        self.token_index = defaultdict(set)
        self.normalized_devices = []
        
        print("Building CPE matching index...")
        self._build_indexes()
        print(f"Index built: {len(self.vendor_index)} vendors, {len(self.model_index)} models, {len(self.token_index)} tokens")
    
    def _build_indexes(self):
        """Build search indexes for faster CPE matching"""
        for idx, device in enumerate(self.devices_data):
            normalized_device = self._normalize_device(device)
            self.normalized_devices.append(normalized_device)
            
            vendor_norm = normalized_device['vendor_normalized']
            if vendor_norm:
                self.vendor_index[vendor_norm].append(idx)
            
            model_components = normalized_device['model_components']
            if model_components['base_model']:
                self.model_index[model_components['base_model']].append(idx)
            
            all_tokens = normalized_device['all_tokens']
            for token in all_tokens:
                if len(token) > 2:
                    self.token_index[token].add(idx)
    
    def _normalize_text(self, text: str) -> str:
        """Enhanced text normalization that handles escaped characters"""
        if not text:
            return ""
        
        text = text.lower()
        text = text.replace('\\/', '/').replace('\\_', '_').replace('\\-', '-')
        text = text.replace('-', ' ').replace('/', ' ').replace('_', ' ')
        text = text.replace('(', ' ').replace(')', ' ')
        text = text.replace('[', ' ').replace(']', ' ')
        text = text.replace(',', ' ').replace('.', ' ')
        text = ' '.join(text.split())
        
        return text
    
    def _extract_model_components(self, model: str) -> Dict[str, any]:
        """Extract components from model string for better matching"""
        if not model:
            return {"base_model": "", "modifiers": [], "full_normalized": "", "original": ""}
        
        normalized = self._normalize_text(model)
        tokens = normalized.split()
        
        base_model = ""
        modifiers = []
        
        for i, token in enumerate(tokens):
            if re.match(r'^[0-9]+[a-z0-9]*$', token):
                base_model = token
                modifiers = tokens[i+1:]
                break
        
        if not base_model and tokens:
            base_model = tokens[0]
            modifiers = tokens[1:]
        
        return {
            "base_model": base_model,
            "modifiers": modifiers,
            "full_normalized": normalized,
            "original": model.lower()
        }
    
    def _normalize_device(self, device: Dict) -> Dict:
        """Pre-normalize device data for faster searching"""
        vendor = device.get('vendor', '')
        model = device.get('model', '')
        title = device.get('title', '')
        device_type = device.get('type', '')
        
        vendor_normalized = self._normalize_text(vendor)
        model_normalized = self._normalize_text(model)
        title_normalized = self._normalize_text(title)
        type_normalized = self._normalize_text(device_type)
        
        model_components = self._extract_model_components(model)
        
        searchable_strings = []
        
        if vendor: searchable_strings.append((vendor.lower(), 0.7))
        if model: searchable_strings.append((model.lower(), 1.0))
        if title: searchable_strings.append((title.lower(), 0.9))
        if device_type: searchable_strings.append((device_type.lower(), 0.6))
        
        if vendor_normalized: searchable_strings.append((vendor_normalized, 0.7))
        if model_normalized: searchable_strings.append((model_normalized, 1.0))
        if title_normalized: searchable_strings.append((title_normalized, 0.9))
        if type_normalized: searchable_strings.append((type_normalized, 0.6))
        
        if vendor and model:
            searchable_strings.extend([
                (f"{vendor.lower()} {model.lower()}", 1.0),
                (f"{vendor_normalized} {model_normalized}", 1.0),
            ])
        
        all_tokens = set()
        for text in [vendor_normalized, model_normalized, title_normalized, type_normalized]:
            if text:
                all_tokens.update(text.split())
        
        return {
            'original_device': device,
            'vendor_normalized': vendor_normalized,
            'model_normalized': model_normalized,
            'title_normalized': title_normalized,
            'type_normalized': type_normalized,
            'model_components': model_components,
            'searchable_strings': searchable_strings,
            'all_tokens': all_tokens
        }
    
    def find_matching_cpe(self, device_name: str, threshold: int = 70) -> List[str]:
        """Find matching CPE using advanced fuzzy logic"""
        device_name_lower = device_name.lower().strip()
        device_name_norm = self._normalize_text(device_name_lower)
        device_tokens = set(device_name_norm.split())
        
        search_components = self._extract_model_components(device_name)
        
        print(f"Searching for: '{device_name}'")
        print(f"Normalized search: '{device_name_norm}'")
        
        candidate_indices = self._get_candidate_devices(device_name)
        print(f"Filtering {len(candidate_indices)} candidates")
        
        if not candidate_indices:
            candidate_indices = set(range(min(5000, len(self.devices_data))))
        
        best_matches = []
        
        for idx in candidate_indices:
            if idx >= len(self.normalized_devices):
                continue
                
            normalized_device = self.normalized_devices[idx]
            device = normalized_device['original_device']
            
            vendor_tokens = set(normalized_device['vendor_normalized'].split()) if normalized_device['vendor_normalized'] else set()
            vendor_match = bool(vendor_tokens.intersection(device_tokens)) if vendor_tokens else True
            
            device_components = normalized_device['model_components']
            model_similarity = self._calculate_model_similarity(search_components, device_components)
            
            device_score = 0
            
            for search_string, weight in normalized_device['searchable_strings']:
                search_string_norm = self._normalize_text(search_string)
                search_tokens = set(search_string_norm.split())
                
                token_overlap = len(device_tokens.intersection(search_tokens))
                total_tokens = len(device_tokens.union(search_tokens))
                token_overlap_score = (token_overlap / total_tokens * 100) if total_tokens > 0 else 0
                
                fuzzy_scores = [
                    fuzz.ratio(device_name_norm, search_string_norm),
                    fuzz.token_sort_ratio(device_name_norm, search_string_norm),
                    token_overlap_score
                ]
                
                max_fuzzy_score = max(fuzzy_scores)
                combined_score = (max_fuzzy_score * 0.6) + (model_similarity * 0.4)
                weighted_score = combined_score * weight
                
                if vendor_tokens:
                    if vendor_match:
                        weighted_score += 10
                    else:
                        weighted_score -= 15
                
                if weighted_score > device_score:
                    device_score = weighted_score
            
            if device_score >= threshold:
                cpe = device.get('cpeName', '').replace("\\/", "/")
                if cpe:
                    best_matches.append((cpe, device_score))
        
        best_matches.sort(key=lambda x: x[1], reverse=True)
        matched_cpes = [cpe for cpe, score in best_matches]
        
        if matched_cpes:
            print(f"Found {len(matched_cpes)} matching CPEs")
        else:
            print(f"No CPE found matching '{device_name}' with threshold {threshold}")
        
        return matched_cpes
    
    def _get_candidate_devices(self, search_query: str) -> Set[int]:
        """Get candidate device indices using indexes"""
        search_normalized = self._normalize_text(search_query)
        search_tokens = set(search_normalized.split())
        search_components = self._extract_model_components(search_query)
        
        candidates = set()
        
        if search_components['base_model']:
            base_model = search_components['base_model']
            if base_model in self.model_index:
                candidates.update(self.model_index[base_model])
        
        token_candidates = set()
        for token in search_tokens:
            if token in self.token_index:
                token_candidates.update(self.token_index[token])
        
        if not candidates:
            candidates = token_candidates
        
        return candidates
    
    def _calculate_model_similarity(self, search_components: Dict, device_components: Dict) -> float:
        """Calculate similarity between search query and device model components"""
        search_base = search_components["base_model"]
        device_base = device_components["base_model"]
        
        if not search_base or not device_base:
            return 0
        
        base_score = fuzz.ratio(search_base, device_base)
        return min(base_score, 100)


class SecurityDataFetcher:
    """Handles external API calls for vulnerability data"""
    
    def __init__(self, api_key: str, max_concurrent: int = 25):
        self.api_key = api_key
        self.max_concurrent = max_concurrent
        self.session: Optional[aiohttp.ClientSession] = None
        self.semaphore = asyncio.Semaphore(max_concurrent)
        self.cwe_cache: Dict[str, Any] = {}
        
    async def __aenter__(self):
        connector = aiohttp.TCPConnector(
            limit=100,
            limit_per_host=50,
            ttl_dns_cache=300,
            use_dns_cache=True,
            keepalive_timeout=30,
            enable_cleanup_closed=True
        )
        timeout = aiohttp.ClientTimeout(total=20, connect=5)
        self.session = aiohttp.ClientSession(
            connector=connector, 
            timeout=timeout,
            headers={'User-Agent': 'SecurityScanner/1.0'}
        )
        return self
        
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if self.session:
            await self.session.close()

    async def fetch_nvd_data(self, cpe_name: str) -> Dict:
        """Fetch CVE data from NVD"""
        url = "https://services.nvd.nist.gov/rest/json/cves/2.0"
        params = {
            "cpeName": cpe_name,
            "startIndex": 0,
            "resultsPerPage": 2000,
        }
        headers = {"apiKey": self.api_key}
        
        print("Fetching NVD data...")
        async with self.semaphore:
            try:
                async with self.session.get(url, params=params, headers=headers) as response:
                    if response.status == 200:
                        return await response.json()
                    else:
                        print(f"NVD API Error: {response.status}")
                        return {}
            except Exception as e:
                print(f"Error fetching NVD data: {e}")
                return {}

    async def fetch_cwe_details_batch(self, cwe_ids: List[str]) -> Dict[str, Any]:
        """Fetch multiple CWE details concurrently"""
        uncached_cwe_ids = [cwe_id for cwe_id in cwe_ids if cwe_id not in self.cwe_cache]
        
        if not uncached_cwe_ids:
            return {cwe_id: self.cwe_cache[cwe_id] for cwe_id in cwe_ids}
        
        print(f"Fetching {len(uncached_cwe_ids)} unique CWE details...")
        
        tasks = []
        for cwe_id in uncached_cwe_ids:
            task = self._fetch_single_cwe(cwe_id)
            tasks.append(task)
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        for cwe_id, result in zip(uncached_cwe_ids, results):
            if isinstance(result, Exception):
                self.cwe_cache[cwe_id] = None
            else:
                self.cwe_cache[cwe_id] = result
        
        return {cwe_id: self.cwe_cache[cwe_id] for cwe_id in cwe_ids}

    async def _fetch_single_cwe(self, cwe_id: str) -> Optional[Dict]:
        """Fetch a single CWE with semaphore control"""
        url = f"https://cwe-api.mitre.org/api/v1/cwe/weakness/{cwe_id}"
        
        async with self.semaphore:
            try:
                async with self.session.get(url) as response:
                    if response.status == 200:
                        return await response.json()
                    return None
            except Exception:
                return None

    async def fetch_epss_scores_batch(self, cve_ids: List[str]) -> Dict[str, float]:
        """Fetch EPSS scores for multiple CVEs in batches"""
        print(f"Fetching EPSS scores for {len(cve_ids)} CVEs...")
        
        batch_size = 50
        all_results = {}
        
        tasks = []
        for i in range(0, len(cve_ids), batch_size):
            batch = cve_ids[i:i + batch_size]
            task = self._fetch_epss_batch(batch)
            tasks.append(task)
        
        batch_results = await asyncio.gather(*tasks, return_exceptions=True)
        
        for result in batch_results:
            if isinstance(result, dict):
                all_results.update(result)
        
        return all_results

    async def _fetch_epss_batch(self, cve_batch: List[str]) -> Dict[str, float]:
        """Fetch EPSS scores for a batch of CVEs"""
        url = "https://api.first.org/data/v1/epss"
        params = {"cve": ",".join(cve_batch)}
        
        async with self.semaphore:
            try:
                async with self.session.get(url, params=params) as response:
                    if response.status == 200:
                        data = await response.json()
                        results = {}
                        for item in data.get("data", []):
                            results[item["cve"]] = float(item["epss"])
                        return results
            except Exception as e:
                print(f"Error fetching EPSS batch: {e}")
            
            return {}


class VulnerabilityDataProcessor:
    """Processes vulnerability data and handles database operations"""
    
    def __init__(self, script_path: str):
        self.script_path = script_path
        self.load_static_data()
        self._build_capec_index()
        self.cpe_matcher = OptimizedCPEMatcher(self.cpes)
        
    def load_static_data(self):
        """Load static data files"""
        print("Loading static data files...")
        
        # Load device CPEs
        device_cpes_path = os.path.join(self.script_path, "hardware_devices.json")
        with open(device_cpes_path, 'r', encoding='utf-8') as f:
            self.cpes = json.load(f)
            
        # Load CAPEC CSV data
        capec_csv_path = os.path.join(self.script_path, "2000CAPEC.csv")
        self.capec_data = []
        try:
            with open(capec_csv_path, 'r', encoding='utf-8') as csvfile:
                reader = csv.DictReader(csvfile)
                self.capec_data = list(reader)
                self.capec_fieldnames = reader.fieldnames
        except FileNotFoundError:
            print(f"CAPEC CSV file not found: {capec_csv_path}")
            
        # Load ATT&CK data - placeholder for now
        attack_json_path = os.path.join(self.script_path, "enterprise-attack.json")
        self.attack_data = {}  # Placeholder - you'll need to implement this
        
        self.headers_to_show = {
            "'ID", "Name", "Description", "Likelihood Of Attack", 
            "Typical Severity", "Related Weaknesses", "Mitigations",
            "Prerequisites", "Consequences", "Example Instances"
        }

    def _build_capec_index(self):
        """Build CAPEC lookup index by CWE"""
        print("Building CAPEC lookup index...")
        self.capec_by_cwe = defaultdict(list)
        
        for row in self.capec_data:
            weakness_data = row.get("Related Weaknesses", "").strip()
            if weakness_data:
                cwe_numbers = re.findall(r'::(\d+)::', weakness_data)
                for cwe_id in cwe_numbers:
                    self.capec_by_cwe[cwe_id].append({
                        "capec_data": {header: row.get(header, "") for header in self.headers_to_show},
                        "taxonomy_mappings": row.get("Taxonomy Mappings", "")
                    })

    def find_matching_cpe(self, input_string: str) -> List[str]:
        """Find matching CPE using enhanced fuzzy logic"""
        return self.cpe_matcher.find_matching_cpe(input_string)

    def process_vulnerabilities_batch(self, vulnerabilities: List[Dict], cpe_name: str) -> Tuple[List[Dict], List[str], Dict[str, List[str]]]:
        """Process all vulnerabilities and extract data"""
        print(f"Processing {len(vulnerabilities)} vulnerabilities...")
        
        processed_cves = []
        all_cve_ids = []
        cve_to_cwes = {}
        
        for cve_item in vulnerabilities:
            if not is_device_vulnerable(cve_item, cpe_name):
                continue

            cve_id = cve_item["cve"]["id"]
            description = cve_item["cve"]["descriptions"][0]["value"]
            
            metrics = self.extract_cve_metrics(cve_item)
            cwe_ids = self.extract_cwes(cve_item)
            
            processed_cves.append({
                "cve_item": cve_item,
                "cve_id": cve_id,
                "description": description,
                "metrics": metrics,
                "cwe_ids": cwe_ids
            })
            
            all_cve_ids.append(cve_id)
            cve_to_cwes[cve_id] = cwe_ids
        
        return processed_cves, all_cve_ids, cve_to_cwes

    def extract_cve_metrics(self, cve_item: Dict) -> Dict:
        """Extract CVSS metrics from CVE data"""
        metrics = cve_item.get("cve", {}).get("metrics", {})
        
        for version in ["cvssMetricV31", "cvssMetricV30", "cvssMetricV2"]:
            if version in metrics:
                metric_data = metrics[version][0]
                return {
                    "cvss": metric_data["cvssData"]["baseScore"],
                    "impact": metric_data["impactScore"],
                    "exploitability": metric_data["exploitabilityScore"]
                }
        
        return {"cvss": 0, "impact": 0, "exploitability": 0}

    def extract_cwes(self, cve_item: Dict) -> List[str]:
        """Extract CWE IDs from CVE data"""
        cwes = []
        for weakness in cve_item["cve"].get("weaknesses", []):
            for desc in weakness.get("description", []):
                cwe_id = desc.get("value", "").split("-")[-1]
                if cwe_id and cwe_id != "noinfo":
                    cwes.append(cwe_id)
        return list(set(cwes))

    def find_related_capec_fast(self, cwe_id: str) -> List[Dict]:
        """Fast CAPEC lookup using pre-built index"""
        return self.capec_by_cwe.get(cwe_id, [])

    @lru_cache(maxsize=500)
    def extract_attack_ids(self, taxonomy_data: str) -> Tuple[str, ...]:
        """Extract MITRE ATT&CK technique IDs with caching"""
        found_entry_ids = re.findall(r'ENTRY ID:([^:]+)', taxonomy_data)
        return tuple(f"T{entry_id}" for entry_id in found_entry_ids)


class DatabaseManager:
    """Handles database operations for vulnerability data"""
    
    def __init__(self, db_session: Session):
        self.db = db_session

    def get_or_create_asset(self, device_info: Dict) -> Asset:
        """Get existing asset or create new one"""
        try:
            # Try to find existing asset
            existing_asset = self.db.query(Asset).filter(
                Asset.vendor == device_info['vendor'],
                Asset.model == device_info['model'],
                Asset.type == device_info['type']
            ).first()
            
            if existing_asset:
                return existing_asset
            
            # Create new asset
            new_asset = Asset(
                type=device_info['type'],
                model=device_info['model'],
                vendor=device_info['vendor'],
                department=device_info.get('department', 'Unknown'),
                risk_level=0.0  # Will be updated later
            )
            
            self.db.add(new_asset)
            self.db.commit()
            self.db.refresh(new_asset)
            return new_asset
            
        except IntegrityError:
            self.db.rollback()
            # If there was a race condition, try to get the existing one
            return self.db.query(Asset).filter(
                Asset.vendor == device_info['vendor'],
                Asset.model == device_info['model'],
                Asset.type == device_info['type']
            ).first()

    def get_or_create_cve(self, cve_data: Dict) -> CVE:
        """Get existing CVE or create new one"""
        try:
            existing_cve = self.db.query(CVE).filter(CVE.cve_id == cve_data['cve_id']).first()
            
            if existing_cve:
                # Update existing CVE data
                existing_cve.description = cve_data['description']
                existing_cve.cvss = cve_data['cvss']
                existing_cve.exploitability = cve_data['exploitability']
                existing_cve.impact = cve_data['impact']
                existing_cve.epss = cve_data['epss']
                existing_cve.risk_level = cve_data['risk_level']
                self.db.commit()
                return existing_cve
            
            new_cve = CVE(
                cve_id=cve_data['cve_id'],
                description=cve_data['description'],
                cvss=cve_data['cvss'],
                exploitability=cve_data['exploitability'],
                impact=cve_data['impact'],
                epss=cve_data['epss'],
                risk_level=cve_data['risk_level']
            )
            
            self.db.add(new_cve)
            self.db.commit()
            self.db.refresh(new_cve)
            return new_cve
            
        except IntegrityError:
            self.db.rollback()
            return self.db.query(CVE).filter(CVE.cve_id == cve_data['cve_id']).first()

    def get_or_create_cwe(self, cwe_data: Dict) -> CWE:
        """Get existing CWE or create new one"""
        try:
            existing_cwe = self.db.query(CWE).filter(CWE.cwe_id == cwe_data['cwe_id']).first()
            
            if existing_cwe:
                # Update existing CWE data
                existing_cwe.name = cwe_data['name']
                existing_cwe.description = cwe_data['description']
                existing_cwe.common_consequenses = cwe_data['common_consequenses']
                existing_cwe.potential_mitigations = cwe_data['potential_mitigations']
                self.db.commit()
                return existing_cwe
            
            new_cwe = CWE(
                cwe_id=cwe_data['cwe_id'],
                name=cwe_data['name'],
                description=cwe_data['description'],
                common_consequenses=cwe_data['common_consequenses'],
                potential_mitigations=cwe_data['potential_mitigations']
            )
            
            self.db.add(new_cwe)
            self.db.commit()
            self.db.refresh(new_cwe)
            return new_cwe
            
        except IntegrityError:
            self.db.rollback()
            return self.db.query(CWE).filter(CWE.cwe_id == cwe_data['cwe_id']).first()

    def get_or_create_capec(self, capec_data: Dict) -> CAPEC:
        """Get existing CAPEC or create new one"""
        try:
            existing_capec = self.db.query(CAPEC).filter(CAPEC.capec_id == capec_data['capec_id']).first()
            
            if existing_capec:
                # Update existing CAPEC data
                for field in ['name', 'description', 'likelihood_of_attack', 'typical_severity', 
                             'related_weaknesses', 'prerequisites', 'mitigations', 'consequences', 
                             'example_instances']:
                    setattr(existing_capec, field, capec_data.get(field))
                self.db.commit()
                return existing_capec
            
            new_capec = CAPEC(
                capec_id=capec_data['capec_id'],
                name=capec_data['name'],
                description=capec_data['description'],
                likelihood_of_attack=capec_data.get('likelihood_of_attack'),
                typical_severity=capec_data.get('typical_severity'),
                related_weaknesses=capec_data.get('related_weaknesses'),
                prerequisites=capec_data.get('prerequisites'),
                mitigations=capec_data.get('mitigations'),
                consequences=capec_data.get('consequences'),
                example_instances=capec_data.get('example_instances')
            )
            
            self.db.add(new_capec)
            self.db.commit()
            self.db.refresh(new_capec)
            return new_capec
            
        except IntegrityError:
            self.db.rollback()
            return self.db.query(CAPEC).filter(CAPEC.capec_id == capec_data['capec_id']).first()

    def get_or_create_attack(self, attack_data: Dict) -> Attack:
        """Get existing Attack or create new one"""
        try:
            existing_attack = self.db.query(Attack).filter(Attack.attack_id == attack_data['attack_id']).first()
            
            if existing_attack:
                # Update existing Attack data
                for field in ['name', 'description', 'platforms', 'tactics', 'data_sources', 
                             'detection', 'permissions_required', 'url']:
                    setattr(existing_attack, field, attack_data.get(field))
                self.db.commit()
                return existing_attack
            
            new_attack = Attack(
                attack_id=attack_data['attack_id'],
                name=attack_data['name'],
                description=attack_data.get('description'),
                platforms=attack_data.get('platforms'),
                tactics=attack_data.get('tactics'),
                data_sources=attack_data.get('data_sources'),
                detection=attack_data.get('detection'),
                permissions_required=attack_data.get('permissions_required'),
                url=attack_data.get('url')
            )
            
            self.db.add(new_attack)
            self.db.commit()
            self.db.refresh(new_attack)
            return new_attack
            
        except IntegrityError:
            self.db.rollback()
            return self.db.query(Attack).filter(Attack.attack_id == attack_data['attack_id']).first()

    def create_relations(self, asset: Asset, cves: List[CVE], cwes: List[CWE], 
                        capecs: List[CAPEC], attacks: List[Attack], cve_to_cwes: Dict[str, List[str]]):
        """Create all necessary relations between entities"""
        
        # Create Asset-CVE relations
        for cve in cves:
            existing_relation = self.db.query(AssetCVERelation).filter(
                AssetCVERelation.asset_id == asset.id,
                AssetCVERelation.cve_id == cve.id
            ).first()
            
            if not existing_relation:
                relation = AssetCVERelation(asset_id=asset.id, cve_id=cve.id)
                self.db.add(relation)
        
        # Create CVE-CWE relations
        for cve in cves:
            cwe_ids = cve_to_cwes.get(cve.cve_id, [])
            for cwe_id in cwe_ids:
                cwe = next((c for c in cwes if c.cwe_id == cwe_id), None)
                if cwe:
                    existing_relation = self.db.query(CVECWERelation).filter(
                        CVECWERelation.cve_id == cve.id,
                        CVECWERelation.cwe_id == cwe.id
                    ).first()
                    
                    if not existing_relation:
                        relation = CVECWERelation(cve_id=cve.id, cwe_id=cwe.id)
                        self.db.add(relation)
        
        # Create CWE-CAPEC relations
        for cwe in cwes:
            related_capecs = [c for c in capecs if cwe.cwe_id in c.related_weaknesses or '']
            for capec in related_capecs:
                existing_relation = self.db.query(CWECAPECRelation).filter(
                    CWECAPECRelation.cwe_id == cwe.id,
                    CWECAPECRelation.capec_id == capec.id
                ).first()
                
                if not existing_relation:
                    relation = CWECAPECRelation(cwe_id=cwe.id, capec_id=capec.id)
                    self.db.add(relation)
        
        # Create CAPEC-Attack relations (placeholder implementation)
        for capec in capecs:
            for attack in attacks:
                existing_relation = self.db.query(CAPECAttackRelation).filter(
                    CAPECAttackRelation.capec_id == capec.id,
                    CAPECAttackRelation.attack_id == attack.id
                ).first()
                
                if not existing_relation:
                    relation = CAPECAttackRelation(capec_id=capec.id, attack_id=attack.id)
                    self.db.add(relation)
        
        self.db.commit()

    def update_asset_risk_level(self, asset: Asset):
        """Calculate and update asset risk level based on associated CVEs"""
        cve_relations = self.db.query(AssetCVERelation).filter(
            AssetCVERelation.asset_id == asset.id
        ).all()
        
        if not cve_relations:
            asset.risk_level = 0.0
        else:
            total_risk = 0.0
            count = 0
            
            for relation in cve_relations:
                cve = self.db.query(CVE).filter(CVE.id == relation.cve_id).first()
                if cve and cve.risk_level:
                    total_risk += cve.risk_level
                    count += 1
            
            asset.risk_level = total_risk / count if count > 0 else 0.0
        
        self.db.commit()


class VulnerabilityScanner:
    """Main scanner class that orchestrates the vulnerability scanning process"""
    
    def __init__(self, nvd_api_key: str, data_path: str):
        self.nvd_api_key = nvd_api_key
        self.data_path = data_path
        self.processor = VulnerabilityDataProcessor(data_path)
    
    async def scan_device(self, device_name: str, department: str = "Unknown", 
                         db_session: Session = None) -> Dict[str, Any]:
        """
        Main scanning function that processes a device and stores results in database
        
        Args:
            device_name: Name of the device to scan
            department: Department owning the device
            db_session: Database session
            
        Returns:
            Dictionary containing scan results and statistics
        """
        if not db_session:
            raise ValueError("Database session is required")
        
        start_time = time.time()
        results = {
            "device_name": device_name,
            "department": department,
            "cpe_matches": [],
            "vulnerabilities_found": 0,
            "cves_processed": 0,
            "cwes_processed": 0,
            "capecs_processed": 0,
            "attacks_processed": 0,
            "scan_time": 0,
            "success": False,
            "error_message": None
        }
        
        try:
            # Initialize database manager
            db_manager = DatabaseManager(db_session)
            
            # Find matching CPE
            cpe_matches = self.processor.find_matching_cpe(device_name)
            if not cpe_matches:
                results["error_message"] = "No matching CPE found for the device"
                return results
            
            results["cpe_matches"] = cpe_matches[:3]  # Store top 3 matches
            print(f"Using CPE: {cpe_matches[0]}")
            
            # Create or get asset record
            # Parse device info from CPE match
            device_info = self._parse_device_info_from_cpe(cpe_matches[0], device_name, department)
            asset = db_manager.get_or_create_asset(device_info)
            
            async with SecurityDataFetcher(self.nvd_api_key, max_concurrent=30) as fetcher:
                # Fetch vulnerability data
                nvd_data = await fetcher.fetch_nvd_data(cpe_matches[0])
                
                if not nvd_data.get("vulnerabilities"):
                    print("No vulnerabilities found for this device")
                    results["success"] = True
                    results["scan_time"] = time.time() - start_time
                    return results
                
                vulnerabilities = nvd_data["vulnerabilities"]
                results["vulnerabilities_found"] = len(vulnerabilities)
                print(f"Found {len(vulnerabilities)} vulnerabilities")
                
                # Process vulnerabilities
                processed_cves, all_cve_ids, cve_to_cwes = self.processor.process_vulnerabilities_batch(
                    vulnerabilities, cpe_matches[0]
                )
                
                if not processed_cves:
                    print("No vulnerabilities affect this specific device")
                    results["success"] = True
                    results["scan_time"] = time.time() - start_time
                    return results
                
                # Get unique CWE IDs
                unique_cwes = list(set(cwe_id for cwe_list in cve_to_cwes.values() for cwe_id in cwe_list))
                
                # Fetch external data concurrently
                print("Fetching external data...")
                epss_task = fetcher.fetch_epss_scores_batch(all_cve_ids)
                cwe_task = fetcher.fetch_cwe_details_batch(unique_cwes)
                
                epss_scores, all_cwe_details = await asyncio.gather(epss_task, cwe_task)
                
                # Process and store data in database
                await self._store_vulnerability_data(
                    db_manager, asset, processed_cves, unique_cwes, 
                    cve_to_cwes, epss_scores, all_cwe_details
                )
                
                # Update statistics
                results["cves_processed"] = len(processed_cves)
                results["cwes_processed"] = len(unique_cwes)
                results["success"] = True
                
        except Exception as e:
            print(f"Error during scan: {str(e)}")
            results["error_message"] = str(e)
            db_session.rollback()
        
        results["scan_time"] = time.time() - start_time
        return results
    
    def _parse_device_info_from_cpe(self, cpe: str, device_name: str, department: str) -> Dict[str, str]:
        """Parse device information from CPE string"""
        # Find matching device in CPE data
        for device in self.processor.cpes:
            if device.get('cpeName', '').replace("\\/", "/") == cpe:
                return {
                    'vendor': device.get('vendor', 'Unknown'),
                    'model': device.get('model', device_name),
                    'type': device.get('type', 'Unknown'),
                    'department': department
                }
        
        # Fallback parsing from CPE string
        cpe_parts = cpe.split(':')
        return {
            'vendor': cpe_parts[3] if len(cpe_parts) > 3 else 'Unknown',
            'model': cpe_parts[4] if len(cpe_parts) > 4 else device_name,
            'type': 'Hardware',
            'department': department
        }
    
    async def _store_vulnerability_data(self, db_manager: DatabaseManager, asset: Asset, 
                                      processed_cves: List[Dict], unique_cwes: List[str],
                                      cve_to_cwes: Dict[str, List[str]], epss_scores: Dict[str, float],
                                      all_cwe_details: Dict[str, Any]):
        """Store all vulnerability data in the database"""
        
        # Store CVEs
        cve_objects = []
        for cve_data in processed_cves:
            cve_id = cve_data["cve_id"]
            epss_score = epss_scores.get(cve_id, 0)
            
            # Calculate risk level
            if epss_score > 0:
                risk_level = epss_score * 1000 * cve_data["metrics"]["impact"] * cve_data["metrics"]["exploitability"]
            else:
                risk_level = 0.0
            
            cve_record_data = {
                'cve_id': cve_id,
                'description': cve_data["description"],
                'cvss': cve_data["metrics"]["cvss"],
                'exploitability': cve_data["metrics"]["exploitability"],
                'impact': cve_data["metrics"]["impact"],
                'epss': epss_score,
                'risk_level': risk_level
            }
            
            cve_obj = db_manager.get_or_create_cve(cve_record_data)
            cve_objects.append(cve_obj)
        
        # Store CWEs
        cwe_objects = []
        for cwe_id in unique_cwes:
            cwe_details = all_cwe_details.get(cwe_id)
            
            if cwe_details and cwe_details.get("Weaknesses"):
                weakness = cwe_details["Weaknesses"][0]
                
                # Format consequences
                consequences = []
                for consequence in weakness.get("CommonConsequences", []):
                    scopes = ", ".join(consequence.get("Scope", []))
                    impacts = ", ".join(consequence.get("Impact", []))
                    consequences.append(f"Scope: {scopes} | Impact: {impacts}")
                
                # Format mitigations
                mitigations = []
                for mitigation in weakness.get("PotentialMitigations", []):
                    phases = ", ".join(mitigation.get("Phase", []))
                    description = mitigation.get("Description", "")
                    mitigations.append(f"Phase: {phases} - {description}")
                
                cwe_record_data = {
                    'cwe_id': cwe_id,
                    'name': weakness.get("Name", f"CWE-{cwe_id}"),
                    'description': weakness.get("Description", ""),
                    'common_consequenses': " | ".join(consequences),
                    'potential_mitigations': " | ".join(mitigations)
                }
            else:
                # Fallback data if API fails
                cwe_record_data = {
                    'cwe_id': cwe_id,
                    'name': f"CWE-{cwe_id}",
                    'description': "Description not available",
                    'common_consequenses': "",
                    'potential_mitigations': ""
                }
            
            cwe_obj = db_manager.get_or_create_cwe(cwe_record_data)
            cwe_objects.append(cwe_obj)
        
        # Store CAPECs
        capec_objects = []
        all_attack_ids = []
        
        for cwe_id in unique_cwes:
            related_capec = self.processor.find_related_capec_fast(cwe_id)
            
            for capec_info in related_capec:
                capec_data = capec_info["capec_data"]
                taxonomy_mappings = capec_info["taxonomy_mappings"]
                
                capec_record_data = {
                    'capec_id': capec_data.get("'ID", ""),
                    'name': capec_data.get("Name", ""),
                    'description': capec_data.get("Description", ""),
                    'likelihood_of_attack': capec_data.get("Likelihood Of Attack", ""),
                    'typical_severity': capec_data.get("Typical Severity", ""),
                    'related_weaknesses': capec_data.get("Related Weaknesses", ""),
                    'prerequisites': capec_data.get("Prerequisites", ""),
                    'mitigations': capec_data.get("Mitigations", ""),
                    'consequences': capec_data.get("Consequences", ""),
                    'example_instances': capec_data.get("Example Instances", "")
                }
                
                if capec_record_data['capec_id']:  # Only create if we have valid ID
                    capec_obj = db_manager.get_or_create_capec(capec_record_data)
                    capec_objects.append(capec_obj)
                    
                    # Extract ATT&CK technique IDs
                    attack_ids = self.processor.extract_attack_ids(taxonomy_mappings)
                    all_attack_ids.extend(attack_ids)
        
        # Store ATT&CK techniques (placeholder implementation)
        attack_objects = []
        unique_attack_ids = list(set(all_attack_ids))
        
        for attack_id in unique_attack_ids:
            # This is a placeholder - you'll need to implement ATT&CK data processing
            attack_record_data = {
                'attack_id': attack_id,
                'name': f"ATT&CK Technique {attack_id}",
                'description': "ATT&CK technique description not available",
                'platforms': "",
                'tactics': "",
                'data_sources': "",
                'detection': "",
                'permissions_required': "",
                'url': f"https://attack.mitre.org/techniques/{attack_id}/"
            }
            
            attack_obj = db_manager.get_or_create_attack(attack_record_data)
            attack_objects.append(attack_obj)
        
        # Create all relations
        db_manager.create_relations(
            asset, cve_objects, cwe_objects, capec_objects, attack_objects, cve_to_cwes
        )
        
        # Update asset risk level
        db_manager.update_asset_risk_level(asset)
        
        print(f"Successfully stored {len(cve_objects)} CVEs, {len(cwe_objects)} CWEs, "
              f"{len(capec_objects)} CAPECs, and {len(attack_objects)} ATT&CK techniques")